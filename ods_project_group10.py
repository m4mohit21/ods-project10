# -*- coding: utf-8 -*-
"""ODS Project Group10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rZzODnjqrK05S0pEaLsi2TADIhQongS1

# Logistic Regression
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

data = pd.read_csv('train.csv')

data.head()

data.columns

X = data[data.columns[:-1]]
y = data['price_range'].copy()

print("Converting Multiclass to Binary Class dataset by reducing Class 1 to Class 0 and Class 2&3 to Class 1")
y[y==1] = 0
y[y==2] =1
y[y==3] =1

X.head()

y.head()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)

print("Scaling the data to avoid overflow in sigmod function")
standardscaler = StandardScaler()
standardscaler.fit(X_train)
X_train = standardscaler.transform(X_train)
X_test = standardscaler.transform(X_test)

print("Training data shape: ",X_train.shape)
print("Testing data shape: ",X_test.shape)

m = np.array([0]*X_train.shape[1],dtype= float)
c= 0
alpha = .1
epoch = 1000*2
loss_data = []
n = len(y_train)
def sigmoid(z):
    sig = 1/(1+np.exp(-z))
    return sig
def cost_func(y,z):
    cost0 = np.dot(y,np.log(sigmoid(z)))
    cost1 = np.dot((1-y),np.log(1-sigmoid(z)))
    cost = -((cost1 + cost0))/len(y)
    return cost

for i in range (epoch):
    z = np.dot(X_train,m) + c
    loss_data.append(cost_func(y_train.values,z))
    y_pred = sigmoid(z)
    m_dash = -1/n *np.sum(X_train*(y_train.values-y_pred).reshape(-1,1),axis=0)
    c_dash = -np.sum(y_train-y_pred)/n
    m -= alpha*m_dash
    c -= alpha*c_dash
print(f"Paramters: {m},\nBias: {c}")

plt.plot(loss_data)
plt.xlabel('Epochs')
plt.ylabel("Loss")
plt.title("Logistic Regression Loss Vs Epochs")
plt.show()

def predict(X):
    z = np.dot(X,m) + c
    lis = []
    i_list = []
    z_list = []
    for i in sigmoid(z):
        if i>0.5:
            lis.append(1)
        else:
            lis.append(0)
        i_list.append(i)
        z_list.append(z)
    return lis,i_list,z_list
def accuracy(y_test,y_pred):
    return np.sum(np.array(y_pred) == y_test)/len(y_test)

y_pred_test,i_list,z_list = predict(X_test)
acc = accuracy(y_test,y_pred_test)
print(f"accuracy of the model on test set after optimizing is {acc*100}%")





# plt.scatter(z_list[0],i_list)
# plt.plot(z_list[0],[0.5]*len(i_list),'r')



